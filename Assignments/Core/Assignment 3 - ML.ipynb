{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Machine Learning\n",
    "**Submitted by -** Prathik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the purpose of the General Linear Model (GLM)?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The General Linear Model (GLM) is a statistical model that is used to model the relationship between a dependent variable and one or more independent variables. The dependent variable is the variable that we are trying to predict, and the independent variables are the variables that we believe are affecting the dependent variable.\n",
    "\n",
    "The GLM is a flexible model that can be used to model a variety of relationships, including linear, logistic, and Poisson relationships. The GLM is also a relatively simple model to understand and interpret, which makes it a popular choice for machine learning practitioners.\n",
    "\n",
    "The purpose of the GLM is to find the best linear combination of the independent variables that predicts the dependent variable. The GLM does this by minimizing the sum of the squared errors between the predicted values and the actual values of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the key assumptions of the General Linear Model?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The General Linear Model (GLM) makes four key assumptions:\n",
    "\n",
    "Linearity: The relationship between the independent variables and the dependent variable is linear. This means that the predicted values of the dependent variable should be a straight line when plotted against the independent variables.\n",
    "\n",
    "Homoskedasticity: The variance of the residuals (the difference between the predicted and actual values of the dependent variable) should be constant across all values of the independent variables. This means that the error terms should be randomly distributed around the mean of zero, and the variance of the error terms should not change as the independent variables change.\n",
    "\n",
    "Normality: The residuals should be normally distributed. This means that the probability of observing a particular value of the residuals should be bell-shaped.\n",
    "\n",
    "Independence: The residuals should be independent of each other. This means that the value of one residual should not affect the value of another residual.\n",
    "\n",
    "If any of these assumptions are violated, the GLM may not be accurate. There are a number of statistical tests that can be used to check the assumptions of the GLM. If the assumptions are violated, there are a number of techniques that can be used to address the violations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How do you interpret the coefficients in a GLM?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The coefficients in a GLM can be interpreted in a variety of ways, depending on the type of GLM that is being used. However, in general, the coefficients can be interpreted as follows:\n",
    "\n",
    "The coefficient for a particular independent variable represents the change in the mean of the dependent variable associated with a change in that variable, while the other variables in the model are held constant.\n",
    "\n",
    "The sign of the coefficient indicates the direction of the relationship between the independent variable and the dependent variable.\n",
    "\n",
    "The magnitude of the coefficient indicates the strength of the relationship between the independent variable and the dependent variable.\n",
    "\n",
    "For example, if a GLM is used to predict the price of a house, and the coefficient for the square footage of the house is positive, then this means that the mean price of a house increases as the square footage of the house increases. The magnitude of the coefficient would indicate how much the mean price of the house increases for each additional square foot of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the difference between a univariate and multivariate GLM?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "\n",
    "The main difference between a univariate and multivariate GLM is the number of dependent variables. A univariate GLM has only one dependent variable, while a multivariate GLM has multiple dependent variables.\n",
    "\n",
    "In a univariate GLM, the goal is to model the relationship between a single independent variable and the dependent variable. For example, a univariate GLM could be used to predict the price of a house based on the square footage of the house.\n",
    "\n",
    "In a multivariate GLM, the goal is to model the relationship between multiple independent variables and multiple dependent variables. For example, a multivariate GLM could be used to predict the price of a house based on the square footage of the house, the number of bedrooms, and the number of bathrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Explain the concept of interaction effects in a GLM.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "An interaction effect in a GLM occurs when the effect of one independent variable on the dependent variable depends on the value of another independent variable. For example, let's say we are interested in the relationship between the amount of time a student studies and their grade on an exam. We might find that the amount of time a student studies has a positive effect on their grade, but that the effect is stronger for students who are also good at taking tests. In this case, we would say that there is an interaction effect between the amount of time studied and the student's test-taking ability.\n",
    "\n",
    "Interaction effects can be difficult to interpret, but they can be very important. For example, if we are trying to predict the success of a new product, we might find that the effect of the product's price on sales depends on the target market. In this case, we would need to consider the interaction effect between price and target market in order to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How do you handle categorical predictors in a GLM?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "\n",
    "Categorical predictors in a GLM can be handled in a few different ways. One way is to create dummy variables for each level of the categorical predictor. For example, if a categorical predictor has three levels, we would create two dummy variables. One dummy variable would indicate whether the observation is in the first level of the categorical predictor, and the other dummy variable would indicate whether the observation is in the second level of the categorical predictor. The third level of the categorical predictor would be the reference level.\n",
    "\n",
    "Another way to handle categorical predictors in a GLM is to use a technique called effect coding. Effect coding creates dummy variables for each level of the categorical predictor, but the coefficients for the dummy variables are not interpreted as the difference between the mean of the dependent variable for a particular level of the categorical predictor and the mean of the dependent variable for the reference level. Instead, the coefficients for the dummy variables are interpreted as the difference between the mean of the dependent variable for a particular level of the categorical predictor and the overall mean of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What is the purpose of the design matrix in a GLM?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The design matrix in a GLM is a matrix that contains the values of the independent variables for each observation. The design matrix is used to calculate the fitted values of the dependent variable, and it is also used to test the significance of the independent variables.\n",
    "\n",
    "The design matrix is typically constructed by creating one column for each independent variable in the model. The values in each column of the design matrix are the values of the independent variable for each observation. For example, if there are two independent variables in the model, then the design matrix will have two columns. The first column will contain the values of the first independent variable for each observation, and the second column will contain the values of the second independent variable for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. How do you test the significance of predictors in a GLM?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The significance of predictors in a GLM can be tested using a variety of methods, including:\n",
    "\n",
    "T-tests: T-tests can be used to test the significance of individual predictors in a GLM. T-tests compare the estimated coefficient for a particular predictor to zero. If the p-value for the t-test is less than a pre-specified significance level, then the predictor is considered to be significant.\n",
    "\n",
    "F-tests: F-tests can be used to test the significance of all of the predictors in a GLM at once. F-tests compare the variance explained by the model to the residual variance. If the p-value for the F-test is less than a pre-specified significance level, then the model is considered to be significant.\n",
    "\n",
    "Likelihood ratio tests: Likelihood ratio tests can be used to compare the fit of two different models. The likelihood ratio test compares the \n",
    "likelihood of the data under the null hypothesis to the likelihood of the data under the alternative hypothesis. If the p-value for the \n",
    "likelihood ratio test is less than a pre-specified significance level, then the alternative hypothesis is considered to be supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Type I, Type II, and Type III sums of squares are different ways of partitioning the total sum of squares in a GLM. The total sum of squares is the sum of the squared deviations of the observed values of the dependent variable from the mean of the dependent variable.\n",
    "\n",
    "Type I sums of squares are the sums of squares for the individual predictors in the model. Type II sums of squares are the sums of squares for the individual predictors, after controlling for the other predictors in the model. Type III sums of squares are the sums of squares for the individual predictors, after controlling for all of the other predictors in the model, including the interactions between the predictors.\n",
    "\n",
    "The main difference between Type I, Type II, and Type III sums of squares is the way that they control for the other predictors in the model. Type I sums of squares do not control for the other predictors, Type II sums of squares control for the other predictors in the model, and Type III sums of squares control for all of the other predictors in the model, including the interactions between the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Explain the concept of deviance in a GLM.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The deviance in a GLM is a measure of how well the model fits the data. The deviance is calculated by comparing the observed values of the dependent variable to the fitted values of the dependent variable. The smaller the deviance, the better the model fits the data.\n",
    "\n",
    "The deviance can also be used to test the significance of the model. If the deviance is significantly different from zero, then the model is considered to be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. What is regression analysis and what is its purpose?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Regression analysis is a statistical method that is used to model the relationship between a dependent variable and one or more independent variables. The dependent variable is the variable that we are trying to predict, and the independent variables are the variables that we believe are affecting the dependent variable.\n",
    "\n",
    "The purpose of regression analysis is to find the best linear combination of the independent variables that predicts the dependent variable. The regression model does this by minimizing the sum of the squared errors between the predicted values and the actual values of the dependent variable.\n",
    "\n",
    "12. What is the difference between simple linear regression and multiple linear regression?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Simple linear regression is a type of regression analysis where there is only one independent variable. Multiple linear regression is a type of regression analysis where there are multiple independent variables.\n",
    "\n",
    "In simple linear regression, the relationship between the dependent variable and the independent variable is modeled by a straight line. In multiple linear regression, the relationship between the dependent variable and the independent variables is modeled by a plane.\n",
    "\n",
    "13. How do you interpret the R-squared value in regression?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The R-squared value is a measure of how well the regression model fits the data. The R-squared value is calculated by comparing the variance of the residuals to the variance of the dependent variable. The closer the R-squared value is to 1, the better the regression model fits the data.\n",
    "\n",
    "14. What is the difference between correlation and regression?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Correlation and regression are both statistical methods that are used to measure the relationship between two variables. However, there are some key differences between the two methods.\n",
    "\n",
    "Correlation measures the strength of the linear relationship between two variables. Regression, on the other hand, measures the strength of the linear relationship between a dependent variable and one or more independent variables.\n",
    "\n",
    "15. What is the difference between the coefficients and the intercept in regression?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The coefficients in a regression model are the weights that are used to combine the independent variables to predict the dependent variable. The intercept in a regression model is the value of the dependent variable when all of the independent variables are equal to zero.\n",
    "\n",
    "16. How do you handle outliers in regression analysis?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Outliers are observations that are significantly different from the rest of the data. Outliers can have a significant impact on the results of a regression analysis.\n",
    "\n",
    "There are a few different ways to handle outliers in regression analysis. One way is to simply remove the outliers from the data. Another way is to transform the data so that the outliers are less extreme.\n",
    "\n",
    "17. What is the difference between ridge regression and ordinary least squares regression?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Ridge regression and ordinary least squares regression are both methods for fitting linear regression models. However, there is one key difference between the two methods.\n",
    "\n",
    "Ridge regression penalizes the coefficients in the regression model. This helps to prevent the coefficients from becoming too large, which can happen when there are multicollinear independent variables.\n",
    "\n",
    "18. What is heteroscedasticity in regression and how does it affect the model?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Heteroscedasticity is a condition where the variance of the residuals is not constant. This can happen when the independent variables are not equally spaced.\n",
    "\n",
    "Heteroscedasticity can affect the results of a regression analysis. If the heteroscedasticity is not addressed, the standard errors of the coefficients may be inaccurate.\n",
    "\n",
    "19. How do you handle multicollinearity in regression analysis?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Multicollinearity is a condition where the independent variables are correlated with each other. This can happen when the independent variables are measuring the same underlying concept.\n",
    "\n",
    "Multicollinearity can affect the results of a regression analysis. If the multicollinearity is not addressed, the standard errors of the coefficients may be inaccurate.\n",
    "\n",
    "20. What is polynomial regression and when is it used?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Polynomial regression is a type of regression analysis where the relationship between the dependent variable and the independent variable is modeled by a polynomial function. Polynomial regression is used when the relationship between the dependent variable and the independent variable is not linear.\n",
    "\n",
    "For example, if the relationship between the dependent variable and the independent variable is quadratic, then a polynomial regression model with a degree of 2 can be used to model the relationship."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
